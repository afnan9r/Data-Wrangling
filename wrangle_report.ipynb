{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8954a6dc",
   "metadata": {},
   "source": [
    "## Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc969d",
   "metadata": {},
   "source": [
    "In this report, we'll describe the steps we followed in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc1015",
   "metadata": {},
   "source": [
    "### The Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e41e5",
   "metadata": {},
   "source": [
    "The data set we wrangled is the tweets archive of the Twitter user @dog_rates, aslo know as We Rate Dogs. The account rates dogs using a numenator that is always higher than the denominator, because \"They're good dogs\". As of September 2021, the account has over 9 million followers on Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33079d93",
   "metadata": {},
   "source": [
    "### Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f66013",
   "metadata": {},
   "source": [
    "The wrangling process starts with (1) Gathering data, then (2) Assessing the collected data and lastly (3) Cleaning the data.\n",
    "\n",
    "#### 1. Gathering Data\n",
    "We gathered data from three different sets using different methods into `twt_archive` DataFrame.\n",
    "1. **The WeRateDogs Twitter archive** was downloaded manullay from Udacity into `img_predicts` DataFrame`\n",
    "2. **The tweet image predictions** was downloaded into a TSV then a pandas DataFrame using the url: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "3. **Additional data from the Twitter API** using the tweet_json.txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2c98f",
   "metadata": {},
   "source": [
    "#### 2. Assessing\n",
    "We assessed the quality and tidiness of the gathered data visually and progammally. Some of the assesment we come up with:\n",
    " \n",
    "**Tidiness Assesment**\n",
    "1. **`tweets_df`** and **`img_predicts`** should be part of **`twt_archive`**.\n",
    "2. Dog's stage variable is divided into 4 columns **`twt_archive`**, when it should be only one.\n",
    "3. ***id*** in **`tweets_df`** should be renamed to ***tweet_id***.\n",
    "\n",
    "**Quality Assesment**\n",
    "1. ***tweet_id*** should not be of data type int64 or float, since we don't do calculations on the ID. Same rule applies to the following columns: ***in_reply_to_status_id***, ***in_reply_to_user_id***, ***retweeted_status_id***, ***retweeted_status_user_id***.\n",
    "2. ***timestamp*** and ***retweeted_status_timestamp*** are of data type string not a datatime.\n",
    "3. Rating denominator should always be 10, the ***rating_denominator*** has other values than 10.\n",
    "4. ***rating_numerator*** has values less than the Rating denominator.\n",
    "5. Missing dogs names (None, a, an)\n",
    "6. 181 of the tweets are retweets, not dog rating tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c318c",
   "metadata": {},
   "source": [
    "#### 3. Cleaning\n",
    "Issues in the assesmnet stage were solved and cleaned, resulting in one clean master data frame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
